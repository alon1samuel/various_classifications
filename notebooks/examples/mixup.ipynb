{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niWkMw9jLc0i"
      },
      "source": [
        "# MixUp augmentation for image classification\n",
        "\n",
        "**Author:** [Sayak Paul](https://twitter.com/RisingSayak)<br>\n",
        "**Date created:** 2021/03/06<br>\n",
        "**Last modified:** 2023/07/24<br>\n",
        "**Description:** Data augmentation using the mixup technique for image classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGsC_5bKLc0n"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbn06Z2oLc0n"
      },
      "source": [
        "_mixup_ is a *domain-agnostic* data augmentation technique proposed in [mixup: Beyond Empirical Risk Minimization](https://arxiv.org/abs/1710.09412)\n",
        "by Zhang et al. It's implemented with the following formulas:\n",
        "\n",
        "![](https://i.ibb.co/DRyHYww/image.png)\n",
        "\n",
        "(Note that the lambda values are values with the [0, 1] range and are sampled from the\n",
        "[Beta distribution](https://en.wikipedia.org/wiki/Beta_distribution).)\n",
        "\n",
        "The technique is quite systematically named. We are literally mixing up the features and\n",
        "their corresponding labels. Implementation-wise it's simple. Neural networks are prone\n",
        "to [memorizing corrupt labels](https://arxiv.org/abs/1611.03530). mixup relaxes this by\n",
        "combining different features with one another (same happens for the labels too) so that\n",
        "a network does not get overconfident about the relationship between the features and\n",
        "their labels.\n",
        "\n",
        "mixup is specifically useful when we are not sure about selecting a set of augmentation\n",
        "transforms for a given dataset, medical imaging datasets, for example. mixup can be\n",
        "extended to a variety of data modalities such as computer vision, naturallanguage\n",
        "processing, speech, and so on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk9WQrb4Lc0o"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VpWGwo1gLc0p"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-08-06 15:56:00.900396: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-06 15:56:00.920583: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-06 15:56:00.926369: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-08-06 15:56:00.940526: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-08-06 15:56:02.079986: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import numpy as np\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras import layers\n",
        "\n",
        "# TF imports related to tf.data preprocessing\n",
        "from tensorflow import data as tf_data\n",
        "from tensorflow import image as tf_image\n",
        "from tensorflow.random import gamma as tf_random_gamma\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kahuwgrmLc0q"
      },
      "source": [
        "## Prepare the dataset\n",
        "\n",
        "In this example, we will be using the [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist) dataset. But this same recipe can\n",
        "be used for other classification datasets as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "THmSFQ0dLc0q"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1722956164.019332   26402 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1722956164.067243   26402 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1722956164.067452   26402 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1722956164.068312   26402 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1722956164.068479   26402 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1722956164.068625   26402 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1722956165.286070   26402 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1722956165.286875   26402 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1722956165.287243   26402 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-08-06 15:56:05.287454: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5955 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_train = np.reshape(x_train, (-1, 28, 28, 1))\n",
        "y_train = keras.ops.one_hot(y_train, 10)\n",
        "\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "x_test = np.reshape(x_test, (-1, 28, 28, 1))\n",
        "y_test = keras.ops.one_hot(y_test, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gArcHG0SLc0r"
      },
      "source": [
        "## Define hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uk0NkigZLc0r"
      },
      "outputs": [],
      "source": [
        "AUTO = tf_data.AUTOTUNE\n",
        "BATCH_SIZE = 4\n",
        "EPOCHS = 2  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8U8bUztLc0s"
      },
      "source": [
        "## Convert the data into TensorFlow `Dataset` objects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vOUlqObELc0s"
      },
      "outputs": [],
      "source": [
        "# Put aside a few samples to create our validation set\n",
        "val_samples = 2000\n",
        "x_val, y_val = x_train[:val_samples], y_train[:val_samples]\n",
        "new_x_train, new_y_train = x_train[val_samples:], y_train[val_samples:]\n",
        "\n",
        "train_ds_one = (\n",
        "    tf_data.Dataset.from_tensor_slices((new_x_train, new_y_train))\n",
        "    .shuffle(BATCH_SIZE * 100)\n",
        "    .batch(BATCH_SIZE)\n",
        ")\n",
        "train_ds_two = (\n",
        "    tf_data.Dataset.from_tensor_slices((new_x_train, new_y_train))\n",
        "    .shuffle(BATCH_SIZE * 100)\n",
        "    .batch(BATCH_SIZE)\n",
        ")\n",
        "# Because we will be mixing up the images and their corresponding labels, we will be\n",
        "# combining two shuffled datasets from the same training data.\n",
        "train_ds = tf_data.Dataset.zip((train_ds_one, train_ds_two))\n",
        "\n",
        "val_ds = tf_data.Dataset.from_tensor_slices((x_val, y_val)).batch(BATCH_SIZE)\n",
        "\n",
        "test_ds = tf_data.Dataset.from_tensor_slices((x_test, y_test)).batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hmayDDLLc0s"
      },
      "source": [
        "## Define the mixup technique function\n",
        "\n",
        "To perform the mixup routine, we create new virtual datasets using the training data from\n",
        "the same dataset, and apply a lambda value within the [0, 1] range sampled from a [Beta distribution](https://en.wikipedia.org/wiki/Beta_distribution)\n",
        "— such that, for example, `new_x = lambda * x1 + (1 - lambda) * x2` (where\n",
        "`x1` and `x2` are images) and the same equation is applied to the labels as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1B7AyBU3Lc0t"
      },
      "outputs": [],
      "source": [
        "\n",
        "def sample_beta_distribution(size, concentration_0=0.2, concentration_1=0.2):\n",
        "    gamma_1_sample = tf_random_gamma(shape=[size], alpha=concentration_1)\n",
        "    gamma_2_sample = tf_random_gamma(shape=[size], alpha=concentration_0)\n",
        "    return gamma_1_sample / (gamma_1_sample + gamma_2_sample)\n",
        "\n",
        "\n",
        "def mix_up(ds_one, ds_two, alpha=0.2):\n",
        "    # Unpack two datasets\n",
        "    images_one, labels_one = ds_one\n",
        "    images_two, labels_two = ds_two\n",
        "    batch_size = keras.ops.shape(images_one)[0]\n",
        "\n",
        "    # Sample lambda and reshape it to do the mixup\n",
        "    l = sample_beta_distribution(batch_size, alpha, alpha)\n",
        "    x_l = keras.ops.reshape(l, (batch_size, 1, 1, 1))\n",
        "    y_l = keras.ops.reshape(l, (batch_size, 1))\n",
        "\n",
        "    # Perform mixup on both images and labels by combining a pair of images/labels\n",
        "    # (one from each dataset) into one image/label\n",
        "    images = images_one * x_l + images_two * (1 - x_l)\n",
        "    labels = labels_one * y_l + labels_two * (1 - y_l)\n",
        "    return (images, labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwgIDojZLc0t"
      },
      "source": [
        "**Note** that here , we are combining two images to create a single one. Theoretically,\n",
        "we can combine as many we want but that comes at an increased computation cost. In\n",
        "certain cases, it may not help improve the performance as well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UB4iJzYLc0t"
      },
      "source": [
        "## Visualize the new augmented dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dG3tE8TmLc0t"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.0, 0.0, 0.0, 0.0, 0.0, 0.868903636932373, 0.13109637796878815, 0.0, 0.0, 0.0]\n",
            "[0.0, 0.0, 0.0, 0.0, 0.001659383182413876, 0.9983406066894531, 0.0, 0.0, 0.0, 0.0]\n",
            "[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "[0.0, 0.9604684710502625, 0.0, 0.0, 0.03953152894973755, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x1000 with 4 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# First create the new dataset using our `mix_up` utility\n",
        "train_ds_mu = train_ds.map(\n",
        "    lambda ds_one, ds_two: mix_up(ds_one, ds_two, alpha=0.2),\n",
        "    num_parallel_calls=AUTO,\n",
        ")\n",
        "\n",
        "# Let's preview 9 samples from the dataset\n",
        "sample_images, sample_labels = next(iter(train_ds_mu))\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i, (image, label) in enumerate(zip(sample_images[:9], sample_labels[:9])):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(image.numpy().squeeze())\n",
        "    print(label.numpy().tolist())\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4awbZkuLc0u"
      },
      "source": [
        "## Model building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OFaFbPHzLc0u"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_training_model():\n",
        "    model = keras.Sequential(\n",
        "        [\n",
        "            layers.Input(shape=(28, 28, 1)),\n",
        "            layers.Conv2D(16, (5, 5), activation=\"relu\"),\n",
        "            layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "            layers.Conv2D(32, (5, 5), activation=\"relu\"),\n",
        "            layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "            layers.Dropout(0.2),\n",
        "            layers.GlobalAveragePooling2D(),\n",
        "            layers.Dense(128, activation=\"relu\"),\n",
        "            layers.Dense(10, activation=\"softmax\"),\n",
        "        ]\n",
        "    )\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJp7fM6DLc0u"
      },
      "source": [
        "For the sake of reproducibility, we serialize the initial random weights of our shallow\n",
        "network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "iXsYOVJ-Lc0u"
      },
      "outputs": [],
      "source": [
        "initial_model = get_training_model()\n",
        "initial_model.save_weights(\"initial_weights.weights.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ynqDeqrLc0u"
      },
      "source": [
        "## 1. Train the model with the mixed up dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "apvCPMsqLc0v"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1722956168.529473   26601 service.cc:146] XLA service 0x73c20000b180 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1722956168.529508   26601 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce GTX 1070, Compute Capability 6.1\n",
            "2024-08-06 15:56:08.572266: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2024-08-06 15:56:09.911780: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
            "2024-08-06 15:56:11.905235: W external/local_xla/xla/service/gpu/nvptx_compiler.cc:762] The NVIDIA driver's CUDA version is 12.0 which is older than the ptxas CUDA version (12.3.107). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m   79/14500\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.1300 - loss: 2.2858      "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0000 00:00:1722956172.491431   26601 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m14500/14500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2ms/step - accuracy: 0.6423 - loss: 1.1250 - val_accuracy: 0.8485 - val_loss: 0.4419\n",
            "Epoch 2/2\n",
            "\u001b[1m14500/14500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2ms/step - accuracy: 0.8022 - loss: 0.7554 - val_accuracy: 0.8575 - val_loss: 0.3869\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8631 - loss: 0.4005\n",
            "Test accuracy: 85.87%\n"
          ]
        }
      ],
      "source": [
        "model = get_training_model()\n",
        "model.load_weights(\"initial_weights.weights.h5\")\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "model.fit(train_ds_mu, validation_data=val_ds, epochs=EPOCHS)\n",
        "_, test_acc = model.evaluate(test_ds)\n",
        "print(\"Test accuracy: {:.2f}%\".format(test_acc * 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvtkbz_bLc0v"
      },
      "source": [
        "## 2. Train the model *without* the mixed up dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "dmJ0rhivLc0v"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m14500/14500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.6831 - loss: 0.8298 - val_accuracy: 0.8470 - val_loss: 0.4361\n",
            "Epoch 2/2\n",
            "\u001b[1m14500/14500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - accuracy: 0.8367 - loss: 0.4385 - val_accuracy: 0.8660 - val_loss: 0.3672\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.8496 - loss: 0.4010\n",
            "Test accuracy: 85.22%\n"
          ]
        }
      ],
      "source": [
        "model = get_training_model()\n",
        "model.load_weights(\"initial_weights.weights.h5\")\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "# Notice that we are NOT using the mixed up dataset here\n",
        "model.fit(train_ds_one, validation_data=val_ds, epochs=EPOCHS)\n",
        "_, test_acc = model.evaluate(test_ds)\n",
        "print(\"Test accuracy: {:.2f}%\".format(test_acc * 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPCib0DLLc0v"
      },
      "source": [
        "Readers are encouraged to try out mixup on different datasets from different domains and\n",
        "experiment with the lambda parameter. You are strongly advised to check out the\n",
        "[original paper](https://arxiv.org/abs/1710.09412) as well - the authors present several ablation studies on mixup\n",
        "showing how it can improve generalization, as well as show their results of combining\n",
        "more than two images to create a single one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3vlflCuLc0v"
      },
      "source": [
        "## Notes\n",
        "\n",
        "* With mixup, you can create synthetic examples — especially when you lack a large\n",
        "dataset - without incurring high computational costs.\n",
        "* [Label smoothing](https://www.pyimagesearch.com/2019/12/30/label-smoothing-with-keras-tensorflow-and-deep-learning/) and mixup usually do not work well together because label smoothing\n",
        "already modifies the hard labels by some factor.\n",
        "* mixup does not work well when you are using [Supervised Contrastive\n",
        "Learning](https://arxiv.org/abs/2004.11362) (SCL) since SCL expects the true labels\n",
        "during its pre-training phase.\n",
        "* A few other benefits of mixup include (as described in the [paper](https://arxiv.org/abs/1710.09412)) robustness to\n",
        "adversarial examples and stabilized GAN (Generative Adversarial Networks) training.\n",
        "* There are a number of data augmentation techniques that extend mixup such as\n",
        "[CutMix](https://arxiv.org/abs/1905.04899) and [AugMix](https://arxiv.org/abs/1912.02781)."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "mixup",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
